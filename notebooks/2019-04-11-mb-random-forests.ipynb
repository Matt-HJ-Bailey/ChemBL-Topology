{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifiers\n",
    "Today I am going to try to implement a random forest classifier on a dataset of activities vs a specific compound.\n",
    "I will split the data into \"Active/Inactive\" classes and then use Morgan Fingerprints as the input for a random forest classifier.\n",
    "\n",
    "## Aims\n",
    "1. Get a classifier with reasonable accuracy\n",
    "\n",
    "## Pitfalls\n",
    "1. Does it even work with boolean vectors?\n",
    "\n",
    "## Todo\n",
    "1. Once the model is built, use the Fibres of Failure Approach to examine it.\n",
    "2. Use a radnom forest regressor to get actual activity data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "\n",
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.AllChem as AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn.ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the hyper-parameters selecting activity cutoffs and which target we wish to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CUTOFF = 5.0\n",
    "DESIRED_TARGETS = [\"CHEMBL240\"]\n",
    "MAPPER_TARGETS = [\"CHEMBL240\", \"CHEMBL264\"]\n",
    "FP_SIZE = 2048\n",
    "VALIDATE_BY_YEAR = False\n",
    "if VALIDATE_BY_YEAR:\n",
    "    YEAR_CUTOFF = 2013\n",
    "else:\n",
    "    VALIDATE_FRACTION = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculate how good the classifier is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy of a given prediction, using the formula\n",
    "    $Acc = \\frac{\\sum \\text{True Positives} + \\sum \\text{True Negatives}}{\\sum \\text{Positives} + \\sum \\text{Negatives}}$\n",
    "    Takes in two numpy array-likes\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(np.logical_and(predictions, ground_truth))\n",
    "    true_negatives = np.sum(np.logical_and(np.logical_not(predictions), np.logical_not(ground_truth)))\n",
    "    size = predictions.shape[0]\n",
    "    return (true_positives + true_negatives) / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates the sensitivity of a given prediction, using the formula\n",
    "    $Acc = \\frac{\\sum \\text{True Positives}}{\\sum \\text{True Positives} + \\sum \\text{False Positives}}$\n",
    "    Takes in two numpy array-likes\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(np.logical_and(predictions, ground_truth))\n",
    "    false_positives = np.sum(np.logical_and(np.logical_not(predictions), ground_truth))\n",
    "    return true_positives / (true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates the specificity of a given prediction, using the formula\n",
    "    $Acc = \\frac{\\sum \\text{True Negatives}}{\\sum \\text{False Positives} + \\sum \\text{True Negatives}}$\n",
    "    Takes in two numpy array-likes\n",
    "    \"\"\"\n",
    "    true_positives = np.sum(np.logical_and(predictions, ground_truth))\n",
    "    true_negatives = np.sum(np.logical_and(np.logical_not(predictions), np.logical_not(ground_truth)))\n",
    "    false_positives = np.sum(np.logical_and(predictions, np.logical_not(ground_truth)))\n",
    "    return (true_negatives) / (false_positives + true_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dissimilarity(vec1, vec2, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Takes in two vectors with values +1 and -1. Computes how far away they are\n",
    "    in according to the metric.\n",
    "    Current metrics:\n",
    "    - Euclidean, computes sqrt(vec1 dot vec2)\n",
    "    - Cosine distance\n",
    "    - Tanimoto\n",
    "    \"\"\"\n",
    "    metric = metric.lower()\n",
    "    if metric == \"euclidean\":\n",
    "        distance = np.abs(vec1 - vec2)\n",
    "        return np.sqrt(np.dot(distance, distance))\n",
    "    \n",
    "    if metric == \"cosine\":\n",
    "        return 1.0 - np.dot(vec1, vec2)/(np.sqrt(np.dot(vec1, vec1)) * np.sqrt(np.dot(vec2, vec2)))\n",
    "                                   \n",
    "    if metric == \"tanimoto\":\n",
    "        return 1.0 - np.dot(vec1, vec2) / (np.dot(vec1, vec1) + np.dot(vec2, vec2) - np.dot(vec1, vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed/curated_set_with_publication_year.pd.pkl\", \"rb\") as infile:\n",
    "    df = pickle.load(infile)\n",
    "\n",
    "possible_targets = Counter([item for item in df[\"TGT_CHEMBL_ID\"]])\n",
    "possible_drugs = Counter([item for item in df[\"CMP_CHEMBL_ID\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3998, 33)\n",
      "(705, 33)\n"
     ]
    }
   ],
   "source": [
    "df = df[np.logical_or.reduce([df[\"TGT_CHEMBL_ID\"] == tgt for tgt in DESIRED_TARGETS])]\n",
    "if VALIDATE_BY_YEAR:\n",
    "    training_df = df[df[\"DOC_YEAR\"] < YEAR_CUTOFF]\n",
    "    validation_df = df[df[\"DOC_YEAR\"] >= YEAR_CUTOFF]\n",
    "else:\n",
    "    df = sklearn.utils.shuffle(df)\n",
    "    split_point = int(df.shape[0] * VALIDATE_FRACTION)\n",
    "    training_df = df.iloc[split_point:, :]\n",
    "    validation_df = df.iloc[:split_point, :]\n",
    "\n",
    "print(training_df.shape)\n",
    "print(validation_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sparse(input_df, use_classes=True):\n",
    "    n_samples = input_df.shape[0]\n",
    "    print(n_samples)\n",
    "    arr = np.empty([n_samples, FP_SIZE], dtype=bool)\n",
    "    if use_classes:\n",
    "        is_active = np.empty([n_samples], dtype=bool)\n",
    "    else:\n",
    "        is_active = np.empty([n_samples], dtype=np.float64)\n",
    "    for index, (item, row) in enumerate(input_df.iterrows()):\n",
    "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(row[\"SMILES\"]),\n",
    "                                                                  radius=3,\n",
    "                                                                  nBits=FP_SIZE)\n",
    "        DataStructs.ConvertToNumpyArray(fingerprint, arr[index, :])\n",
    "        if use_classes:\n",
    "            if row[\"BIOACT_PCHEMBL_VALUE\"] < ACTIVITY_CUTOFF:\n",
    "                is_active[index] = False\n",
    "            else:\n",
    "                is_active[index] = True\n",
    "        else:\n",
    "            is_active[index] = row[\"BIOACT_PCHEMBL_VALUE\"]\n",
    "\n",
    "    observations = scipy.sparse.csc_matrix(arr)\n",
    "    return observations, is_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998\n",
      "705\n"
     ]
    }
   ],
   "source": [
    "training_observations, training_is_active = convert_to_sparse(training_df)\n",
    "validation_observations, validation_is_active = convert_to_sparse(validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does the n_estimators parameter actually matter?\n",
    "Answer: 1024 seems to be just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7971631205673759"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=512, criterion=\"gini\", n_jobs=4, bootstrap=False, max_features=\"log2\")\n",
    "model.fit(training_observations, training_is_active)\n",
    "model.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=1024, criterion=\"gini\", n_jobs=4, bootstrap=False, max_features=\"log2\")\n",
    "model.fit(training_observations, training_is_active)\n",
    "model.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957446808510639"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=2048, criterion=\"gini\", n_jobs=4, bootstrap=False, max_features=\"log2\")\n",
    "model.fit(training_observations, training_is_active)\n",
    "model.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(n_estimators=4096, criterion=\"gini\", n_jobs=4, bootstrap=False, max_features=\"log2\")\n",
    "model.fit(training_observations, training_is_active)\n",
    "model.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do other classifiers fit the data? ExtraTrees is good in the case of few important features and lots of noisy features, but equivalent otherwise.\n",
    "\n",
    "Answer: it scores pretty similarly, within the margin of error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.ensemble.ExtraTreesClassifier(n_estimators=2048, criterion=\"gini\", n_jobs=4, bootstrap=False, max_features=\"log2\")\n",
    "model.fit(training_observations, training_is_active)\n",
    "model.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7680851063829788\n",
      "Sensitivity = 0.7848101265822784\n",
      "Specificity = 0.375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy =\", accuracy(predictions, validation_is_active))\n",
    "print(\"Sensitivity =\", sensitivity(predictions, validation_is_active))\n",
    "print(\"Specificity =\", specificity(predictions, validation_is_active))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = sklearn.ensemble.RandomForestRegressor(n_estimators=1024, criterion=\"mse\", verbose=1, n_jobs=4, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3998\n",
      "705\n"
     ]
    }
   ],
   "source": [
    "training_observations, training_is_active = convert_to_sparse(training_df, use_classes=False)\n",
    "validation_observations, validation_is_active = convert_to_sparse(validation_df, use_classes=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get useful regression information? (Warning: Takes 6 minutes, and the answer is \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=4)]: Done 1024 out of 1024 | elapsed:  6.3min finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1024 out of 1024 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5116423089924126"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(training_observations, training_is_active)\n",
    "regressor.score(validation_observations, validation_is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vector_df.pkl\", \"rb\") as fi:\n",
    "    vector_df = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "50 631\n",
      "100 1908\n",
      "150 1908\n",
      "Looking at Chembl 240\n",
      "165\n",
      "200 1989\n",
      "250 1989\n",
      "300 1989\n",
      "350 1989\n",
      "400 1989\n",
      "450 1989\n",
      "500 1989\n",
      "550 1989\n",
      "600 1989\n",
      "650 1989\n",
      "700 1989\n",
      "750 1989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-fe5ebf206c4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mother_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mother_drugs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mother_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdrugs_shared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrugs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_drugs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdrugs_shared\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_drugs_shared\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmax_drugs_shared\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrugs_shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/chembl-topology/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2076\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/anaconda3/envs/chembl-topology/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_drugs_shared = 0\n",
    "for index in range(len(vector_df.index)):\n",
    "    if vector_df.iloc[index].name == \"CHEMBL240\":\n",
    "        print(\"Looking at Chembl 240\")\n",
    "        print(index)\n",
    "    drugs = np.abs(vector_df.iloc[index].values)\n",
    "    if (index % 50 == 0):\n",
    "        print(index, max_drugs_shared)\n",
    "    for other_index in range(index):\n",
    "        other_drugs = np.abs(vector_df.iloc[other_index].values)\n",
    "        drugs_shared = np.sum(np.logical_and(drugs.astype(bool), other_drugs.astype(bool)))\n",
    "        if drugs_shared > max_drugs_shared:\n",
    "            max_drugs_shared = drugs_shared\n",
    "            max_coords = (index, other_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_drugs_shared = 0\n",
    "chembl_240_drugs = np.abs(vector_df.iloc[165].values)\n",
    "for index in range(len(vector_df.index)):\n",
    "    if index == 165:\n",
    "        continue\n",
    "    other_drugs = np.abs(vector_df.iloc[index].values)\n",
    "    drugs_shared = np.sum(np.logical_and(chembl_240_drugs.astype(bool), other_drugs.astype(bool)))\n",
    "    if drugs_shared > max_drugs_shared:\n",
    "        max_drugs_shared = drugs_shared\n",
    "        max_coords = (165, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 142) 352\n"
     ]
    }
   ],
   "source": [
    "print(max_coords, max_drugs_shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHEMBL264\n"
     ]
    }
   ],
   "source": [
    "print(vector_df.iloc[142].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rdDepictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-76741831de32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmolec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SMILES\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mchembl_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CMP_CHEMBL_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrdDepictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompute2DCoords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdrawer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdMolDraw2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolDraw2DSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdrawer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDrawMolecule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmolec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rdDepictor' is not defined"
     ]
    }
   ],
   "source": [
    "for index, series in df[np.logical_or.reduce([df[\"TGT_CHEMBL_ID\"] == tgt for tgt in MAPPER_TARGETS])].iterrows():\n",
    "    molec = Chem.MolFromSmiles(series[\"SMILES\"])\n",
    "    chembl_id = series[\"CMP_CHEMBL_ID\"]\n",
    "    rdDepictor.Compute2DCoords(molec)\n",
    "    drawer = rdMolDraw2D.MolDraw2DSVG(250, 250)\n",
    "    drawer.DrawMolecule(molec)\n",
    "    drawer.FinishDrawing()\n",
    "    svg = drawer.GetDrawingText()\n",
    "    with open(f\"./Figures/{chembl_id}.svg\", \"w\") as svgfile:\n",
    "        svgfile.write(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = vector_df.T[np.logical_or.reduce([vector_df.loc[tgt].values != 0 for tgt in MAPPER_TARGETS])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew-bailey/Applications/anaconda3/envs/chembl-topology/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in byte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "distance_matrix = np.zeros([len(sub_df), len(sub_df)])\n",
    "for drug_index in range(len(sub_df)):\n",
    "    if not drug_index % 100:\n",
    "        print(drug_index)\n",
    "    drug = sub_df.iloc[drug_index].values\n",
    "    for other_index in range(drug_index):\n",
    "        other_drug = sub_df.iloc[other_index].values\n",
    "        distance = dissimilarity(drug, other_drug, \"tanimoto\")\n",
    "        distance_matrix[drug_index, other_index] = distance\n",
    "        distance_matrix[other_index, drug_index] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
