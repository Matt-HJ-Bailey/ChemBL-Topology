{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Topological Data Analysis is a method to simplify highly complex and many-dimensional data.\n",
    "It does this by clustering datapoints and considering the connections between them. This was\n",
    "first used by Singh, MÃ©moli and Carlson in 2007 with the `Mapper` algorithm.\\cite{Singh2007}\n",
    "More recently, it has been implemented in a variety of packages such as (...list...)\n",
    "In this work, I use the `KeplerMapper` implementation in `Python`.\\cite{KeplerMapper}\n",
    "\n",
    "The clustering is performed by the `HDBSCAN` algorithm, because it copes well with\n",
    "changes in the density of datapoints.\\cite{McInnes2017}\n",
    "\n",
    "## Related Works\n",
    "Discuss `FIFA` paper, BitterSweet Forest, etc.\n",
    "Do a literature review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory and Computational Method\n",
    "## Theory\n",
    "In this section, I will discuss the theory of topological data\n",
    "analysis. A simple figure demonstrating it will be helpful,\n",
    "as well as some maths chat. The Fibres of Failure paper \n",
    "is good for that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational Method\n",
    "All of the computational work in this report was done using `Python 3.7` and the Jupyter notebook.\n",
    "This was chosen because of the range of available software packages, and its ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from IPython.display import SVG, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_TARGETS = [\"CHEMBL240\"]\n",
    "\n",
    "# To ensure repeatability of runs, the random seed should\n",
    "# be consistent.\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Data splitting hyperparameters.\n",
    "TRAIN_RF_FRACTION = 0.60\n",
    "TRAIN_FIFA_FRACTION = 0.20\n",
    "VALIDATE_FRACTION = 1.0 - TRAIN_FIFA_FRACTION - TRAIN_RF_FRACTION\n",
    "\n",
    "# Community detection hyperparameters.\n",
    "# Discard any with too small a set of nodes,\n",
    "# or too small a prediction error.\n",
    "COMMUNITY_SIZE_CUTOFF = 3\n",
    "COMMUNITY_ERROR_CUTOFF = 0.20\n",
    "CORRECTION_STD_WARN = 0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this work was taken from a sanitised version of the ChEMBL database created by Lenselink *et al*. \\cite{Gaulton2012, Lenselink2017} This dataset contains only the entries in ChEMBL that have minimal experimental error, confident numerical ratings and no duplicate measurements. From this dataset, I used RDKit to parse chemical information into a computationally-accessible format.\\cite{rdkit} The drugs were converted into SMILES strings, and their chemical fingerprints were calculted using a Morgan Fingerprinting algorithm with\n",
    "a fingerprint radius of 3 bonds and a fingerprint size of 2048 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVITY_CUTOFF = 6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the dataset, activity is quantified by a `pChEMBL` value, which is logarithmic and ranges between 1 and 10. Examples in the literature often demarcate \"active\" vs \"inactive\" at `pChEMBL = 5.0`, but this classifies 90% of \n",
    "compounds in the dataset as active. Instead, `pChEMBL = 6.5` is used as a cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_SIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.AllChem as AllChem\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import DataStructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_location = \"../data/processed/curated_set_with_publication_year.pd.pkl\"\n",
    "with open(input_location, \"rb\") as infile:\n",
    "    df = pickle.load(infile)\n",
    "\n",
    "possible_targets = Counter([item for item in df[\"TGT_CHEMBL_ID\"]])\n",
    "possible_drugs = Counter([item for item in df[\"CMP_CHEMBL_ID\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    target = row[\"TGT_CHEMBL_ID\"]\n",
    "    if target in DESIRED_TARGETS:\n",
    "        drug = row[\"CMP_CHEMBL_ID\"]\n",
    "        molec = Chem.MolFromSmiles(row[\"SMILES\"])\n",
    "        fingerprint_dict[drug] = AllChem.GetMorganFingerprintAsBitVect(molec,\n",
    "                                                                       radius=3,\n",
    "                                                                       nBits=FP_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used KeplerMapper to perform the topological data analysis.\\cite{KeplerMapper} This is a free and open source\n",
    "implementation of the Mapper algorithm which runs in `Python`. To do further graph manipulations including community detection, I used the `igraph` package.\\cite{igraph}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmapper as km\n",
    "import igraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topological data analysis requires an algorithm to cluster the datapoints into nodes. I used the HDBSCAN algorithm\n",
    "to perform this task, because it is designed to cope well with varying densities of data points. This is important for analysis of chemical space, because the density of experimental data is often inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "clusterer = hdbscan.HDBSCAN(metric='precomputed', min_cluster_size=3, min_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I used Scikit-Learn to do to the machine learning in this work.\\cite{scikit-learn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Results\n",
    "## Exploring Chemical Space\n",
    "One powerful way to use topological data analysis is to explore the similarities in chemical space in a human-readable form. To do so, we must quantify the \"distance\" between two compounds in chemical space. I have\n",
    "chosen to do so with the Tanimoto Similarity, which is\n",
    "\\begin{equation}\n",
    "   d_T = \\frac{M_{11}}{M_{10} + M_{01} - M_{11}}\n",
    "\\end{equation}\n",
    "with $ M_{11} $ being the number of shared 1s in two fingerprints and $M_{10} + M_{01} $ being the number of 1s in one fingerprint but not in the other.\n",
    "\n",
    "Generating the distance matrix for a set of compounds is an $\\order{N^2} $ operation in both time and memory. The\n",
    "distance matrix calculation was the limiting factor for the amount of data I could analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem_space_df = df[np.logical_or.reduce([df[\"TGT_CHEMBL_ID\"] == tgt for tgt in DESIRED_TARGETS])]\n",
    "chem_space_df = sklearn.utils.shuffle(chem_space_df, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n"
     ]
    }
   ],
   "source": [
    "distance_matrix = np.zeros([len(chem_space_df), len(chem_space_df)])\n",
    "for index in range(len(chem_space_df)):\n",
    "    if not index % 100:\n",
    "        print(index)\n",
    "    drug = chem_space_df.iloc[index][\"CMP_CHEMBL_ID\"]\n",
    "    fp_1 = fingerprint_dict[drug]\n",
    "    for other_index in range(index):\n",
    "        other_drug = chem_space_df.iloc[other_index][\"CMP_CHEMBL_ID\"]\n",
    "        fp_2 = fingerprint_dict[other_drug]\n",
    "        distance = 1.0 - rdkit.DataStructs.TanimotoSimilarity(fp_1, fp_2)\n",
    "        distance_matrix[drug_index, other_index] = distance\n",
    "        distance_matrix[other_index, drug_index] = distance\n",
    "pickle.dump(distance_matrix, open(\"chemical-space-distance.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(distance_matrix, zorder=2, cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key feature of topological data analysis that makes it useful to explore chemical space is that it shows low-dimensional data while keeping the links of high-dimensional data. Here, I use Multi-Dimensional Scaling (MDS) to reduce the dimensionality of the data to two principal components. MDS works very similarly to principal component analysis, but is applicable to more general spaces (such as non-metric chemical space).\\cite{Martin2015}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds_cooordinate = MDS(n_components=2, dissimilarity=\"precomputed\", metric=False).fit_transform(distance_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
